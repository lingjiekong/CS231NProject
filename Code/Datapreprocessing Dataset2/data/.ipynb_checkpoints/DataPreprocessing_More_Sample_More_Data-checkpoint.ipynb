{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is used for a test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2, simplejson, os, shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fileName = '20170507T155114.708081'\n",
    "fileNameVideo = fileName + '.avi'\n",
    "vidcap = cv2.VideoCapture(fileNameVideo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'end-frame': 111,\n",
       "  'event-class': '0 added',\n",
       "  'object-class': 'Clover Organic 2% Milk',\n",
       "  'start-frame': 81},\n",
       " {'end-frame': 135,\n",
       "  'event-class': '1 removed',\n",
       "  'object-class': 'Clover Organic 2% Milk',\n",
       "  'start-frame': 111},\n",
       " {'end-frame': 176,\n",
       "  'event-class': '0 added',\n",
       "  'object-class': 'Horizon Organic Chocolate Milk',\n",
       "  'start-frame': 141},\n",
       " {'end-frame': 196,\n",
       "  'event-class': '1 removed',\n",
       "  'object-class': 'Horizon Organic Chocolate Milk',\n",
       "  'start-frame': 176},\n",
       " {'end-frame': 228,\n",
       "  'event-class': '0 added',\n",
       "  'object-class': 'Horizon Organic Chocolate Milk',\n",
       "  'start-frame': 208},\n",
       " {'end-frame': 264,\n",
       "  'event-class': '1 removed',\n",
       "  'object-class': 'Horizon Organic Chocolate Milk',\n",
       "  'start-frame': 234}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fileNameEvents = fileName + '-events.json'\n",
    "events = simplejson.loads(open(fileNameEvents).read())\n",
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 81 111 141 176 208 234]\n",
      "[110 134 175 195 227 263]\n",
      "[0, 3, 0, 3, 0, 3]\n"
     ]
    }
   ],
   "source": [
    "dataDict = {}\n",
    "dataDict['data'] = []\n",
    "dataDict['label'] = []\n",
    "frames_start =[]\n",
    "frames_end = []\n",
    "for idx, event in enumerate(events):\n",
    "    if event['event-class'] == '0 added':\n",
    "        frames_start.append(event['start-frame'])\n",
    "        frames_end.append(event['end-frame']-1)\n",
    "        dataDict['label'].append(0)\n",
    "    elif event['event-class'] == '0 removed':\n",
    "        frames_start.append(event['start-frame'])\n",
    "        frames_end.append(event['end-frame']-1)\n",
    "        dataDict['label'].append(1)\n",
    "    elif event['event-class'] == '1 added':\n",
    "        frames_start.append(event['start-frame'])\n",
    "        frames_end.append(event['end-frame']-1)\n",
    "        dataDict['label'].append(2)\n",
    "    elif event['event-class'] == '1 removed':\n",
    "        frames_start.append(event['start-frame'])\n",
    "        frames_end.append(event['end-frame']-1)\n",
    "        dataDict['label'].append(3)\n",
    "frames_start = np.array(frames_start)\n",
    "frames_end = np.array(frames_end)\n",
    "print(frames_start)\n",
    "print(frames_end)\n",
    "print (dataDict['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  88.  112.  141.  178.  209.  238.]\n",
      " [  93.  114.  149.  187.  210.  243.]\n",
      " [ 102.  118.  154.  188.  211.  249.]\n",
      " [ 104.  124.  157.  189.  214.  252.]\n",
      " [ 109.  126.  160.  190.  218.  255.]]\n"
     ]
    }
   ],
   "source": [
    "def get_frames(n, frames_start, frames_end):\n",
    "    frames = np.zeros((n,frames_start.shape[0]))\n",
    "    for i in range(frames_start.shape[0]):\n",
    "        var = random.sample(range(int(frames_start[i]), int(frames_end[i])), n)\n",
    "        var = np.sort(var)\n",
    "        frames[:,i] = var\n",
    "    frames = np.floor(frames)\n",
    "    return frames\n",
    "frames = get_frames(5, frames_start, frames_end)\n",
    "print (frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  83.  120.  145.  180.  211.  234.]\n",
      " [  89.  123.  151.  181.  218.  240.]\n",
      " [  93.  124.  163.  183.  223.  251.]\n",
      " [ 102.  127.  166.  191.  225.  255.]\n",
      " [ 107.  131.  171.  193.  226.  256.]]\n",
      "[[  92.  112.  142.  178.  209.  241.]\n",
      " [  93.  115.  144.  184.  214.  243.]\n",
      " [  98.  120.  154.  185.  216.  253.]\n",
      " [  99.  124.  158.  188.  221.  255.]\n",
      " [ 101.  125.  169.  191.  223.  259.]]\n"
     ]
    }
   ],
   "source": [
    "num_frame_per_video = 5\n",
    "num_sample_per_video = 10\n",
    "\n",
    "inputSize = 224\n",
    "dirname = 'img'\n",
    "data_len = frames_start.shape[0]\n",
    "vidcap = cv2.VideoCapture(fileNameVideo)\n",
    "if not os.path.isdir(dirname):\n",
    "    os.mkdir(dirname)\n",
    "\n",
    "for j in range(num_sample_per_video):\n",
    "    frames = get_frames(num_frame_per_video, frames_start, frames_end)\n",
    "    print (frames)\n",
    "    for i in range(data_len):\n",
    "        vidcap = cv2.VideoCapture(fileNameVideo)\n",
    "        success,image = vidcap.read()\n",
    "        count = 0\n",
    "        success = True\n",
    "        one_data = []\n",
    "        while success:\n",
    "            success,image = vidcap.read()\n",
    "            #print('Read a new frame: '), success\n",
    "            if np.any(frames[:,i] == count):\n",
    "                image_crop = image[100:500, 150:800]\n",
    "                image_down = cv2.resize(image_crop, dsize=(inputSize,inputSize), interpolation = cv2.INTER_CUBIC)\n",
    "                imageFileName = '%s/f%d.jpg' % (dirname, count)\n",
    "                cv2.imwrite(imageFileName, image_down)     # save frame as JPEG file\n",
    "                one_data.append(image_down)\n",
    "            count += 1\n",
    "        dataDict['data'].append(one_data)\n",
    "        vidcap.release()\n",
    "dataDict['label'] = dataDict['label']*num_sample_per_video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (np.array(dataDict['label']).shape)\n",
    "print (np.array(dataDict['data']).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = img.imread('img/f%d.jpg' % np.random.choice(frames.reshape(frames.size)))\n",
    "plt.imshow(f)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real data preprocessing starts from here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "dataDict = {}\n",
    "dataDict['data'] = []\n",
    "dataDict['label'] = []\n",
    "video_count = 0\n",
    "\n",
    "for filename in os.listdir('.'):\n",
    "    \n",
    "    if filename.endswith('.avi'): \n",
    "        print (video_count)\n",
    "        video_count += 1\n",
    "        \n",
    "        fileName = os.path.splitext(filename)[0]\n",
    "        \n",
    "        # read json\n",
    "        fileNameEvents = fileName + '-events.json'\n",
    "        events = simplejson.loads(open(fileNameEvents).read())\n",
    "        \n",
    "        # store start/end frames and labels            \n",
    "        frames_start =[]\n",
    "        frames_end = []\n",
    "        temp_label_list = []\n",
    "        for idx, event in enumerate(events):\n",
    "            if event['event-class'] == '0 added':\n",
    "                frames_start.append(event['start-frame'])\n",
    "                frames_end.append(event['end-frame']-1)\n",
    "                temp_label_list.append(0)\n",
    "            elif event['event-class'] == '0 removed':\n",
    "                frames_start.append(event['start-frame'])\n",
    "                frames_end.append(event['end-frame']-1)\n",
    "                temp_label_list.append(1)\n",
    "            elif event['event-class'] == '1 added':\n",
    "                frames_start.append(event['start-frame'])\n",
    "                frames_end.append(event['end-frame']-1)\n",
    "                temp_label_list.append(2)\n",
    "            elif event['event-class'] == '1 removed':\n",
    "                frames_start.append(event['start-frame'])\n",
    "                frames_end.append(event['end-frame']-1)\n",
    "                temp_label_list.append(3)\n",
    "            \n",
    "        frames_start = np.array(frames_start)\n",
    "        frames_end = np.array(frames_end)\n",
    "            \n",
    "        # make a separate image folder\n",
    "        if not os.path.isdir('img'):\n",
    "            os.mkdir('img')\n",
    "        temp = 'img/%s' % fileName\n",
    "        if not os.path.isdir(temp):\n",
    "            os.mkdir(temp)\n",
    "            \n",
    "        # num sample per video\n",
    "        num_sample_per_video = 5\n",
    "        num_frame_per_video = 1\n",
    "        dataDict['label'] += temp_label_list*num_sample_per_video\n",
    "        for j in range(num_sample_per_video):\n",
    "            # sample frame indices\n",
    "            frames = get_frames(num_frame_per_video, frames_start, frames_end)\n",
    "            for i in range(frames_start.shape[0]):\n",
    "                # load video\n",
    "                fileNameVideo = fileName + '.avi'\n",
    "                vidcap = cv2.VideoCapture(fileNameVideo)\n",
    "\n",
    "                # data augmentation\n",
    "                inputSize = 224 # for squeeze net input\n",
    "                success,image = vidcap.read()\n",
    "                count = 0\n",
    "                success = True\n",
    "                one_data = []\n",
    "                while success:\n",
    "                    success,image = vidcap.read()\n",
    "                    if np.any(frames[:,i] == count):\n",
    "                        # center crop\n",
    "                        image_crop = image[100:500, 150:800]\n",
    "                        # downsampling\n",
    "                        image_down = cv2.resize(image_crop, dsize=(inputSize,inputSize), interpolation = cv2.INTER_CUBIC)\n",
    "                        one_data.append(image_down)\n",
    "                        # write image\n",
    "                        # imageFileName = 'img/%s/f%d.jpg' % (fileName, count)\n",
    "                        # cv2.imwrite(imageFileName, image_down)     # save frame as JPEG file\n",
    "                    count += 1\n",
    "                dataDict['data'].append(one_data)\n",
    "                vidcap.release()\n",
    "        \n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (np.array(dataDict['label']).shape)\n",
    "print (np.array(dataDict['data']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# efficent save in npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from tempfile import TemporaryFile\n",
    "np.save('data_1_frame_more_data.npy', dataDict['data'])\n",
    "np.save('label_1_frame_more_data.npy', dataDict['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# efficient load in npy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.load(\"data_5_frame.npy\")\n",
    "label = np.load(\"label_5_frame.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# test dimension again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60,)\n",
      "(60, 5, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print (np.array(dataDict['label']).shape)\n",
    "print (np.array(dataDict['data']).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save result in Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "# each separate dict()\n",
    "with open('label_squeeze.json', 'w') as fp:\n",
    "    json.dump(np.array(dataDict['label']).tolist(), fp, indent=4)\n",
    "with open('data_squeeze.json', 'w') as fp:\n",
    "    json.dump(np.array(dataDict['data']).tolist(), fp, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load result in Json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('label_squeeze.json', 'r') as fp:\n",
    "    label_load = json.load(fp)\n",
    "with open('data_squeeze.json', 'r') as fp:\n",
    "    data_load = json.load(fp)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflowroot]",
   "language": "python",
   "name": "conda-env-tensorflowroot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
